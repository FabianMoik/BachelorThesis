%%%% Time-stamp: <2013-02-25 10:31:01 vk>


\chapter{State-Of-The-Art}
\label{cha:State-Of-The-Art}
The game of poker has many interesting properties which proved to offer a challenging test environment for artificial intelligence research. Over the last decade scientists and researchers have studied the game from a game theoretical view to find optimal solutions but also tried a number of machine learning algorithms and artificial intelligence systems on the game \cite{opp_master, challenge_of_poker}. A lot of research though focused on simplified versions of the game because these variants of poker are easier to analyze but still offer demonstrations of game theoretical principles \cite{challenge_of_poker}. Nonetheless over the past few years, abstract versions of poker have been used to first successfully train algorithms on this simple version of the game and then transfer the obtained knowledge to a full version of the game \cite{opp_master, challenge_of_poker}.
\section{Knowledge-based Poker Agents}
Knowledge-based systems can be broken into two categories, namely \textbf{rule-based expert systems} and \textbf{formula-based methods}. In general knowledge-based systems require the knowledge of an expert player to design the system \cite{review}. A \textit{rule-based expert system} in its simplest form is a sequence of if-else statements for frequently occurring scenarios of the game which determine the desirable \pokerterm{betting action}. More advanced human players describe their poker hands in a very similar way when they break them down in a discussion \cite{master_nuno}. \textit{Formula-based methods} on the other hand try to generalize the problem by defining a formula that takes a set of inputs and outputs a so-called \pokerterm{probability triple} upon which a betting decision is made. Inputs to the formula may describe important information about the current game state and can be weighted to reinforce the importance of certain inputs over others \cite{review}. \par
While rule-based expert systems may yield reasonably good results in the first stage of a poker hand (pre-flop), they fail to shine in later stages of the game because they become increasingly difficult to maintain with additional and sometimes even conflicting information added at each stage. Furthermore  static strategies are prone to exploitation and therefore not competitive with other approaches \cite{review}.
\section{Simulation-based Poker Agents}
In general simulation based methods rely on repeatedly simulating an outcome in order to approximate the resulting expected value of an action \cite{master_nuno}. A frequently used simulation method applied to the game of poker is the so called \textit{Monte-Carlo simulation} or \textit{Monte-Carlo Tree Search}, which is a procedure that searches the game tree by sampling the possible choices in a game state and simulates the action taken to the bottom of the tree. By repeating this procedure a robust expectation value can be computed \cite{review}. 
In Billings \textit{et. al} \cite{selective_sampling}, the technique of \textit{selective sampling} is described, which uses information about the opponents to bias the selection of possible card combinations a player may hold. With this modification to the sampling algorithm they were able to create a more dynamic betting strategy due to the gain of valuable information about opponents. 
\section{Game-Theoretic Optimal Poker Agents}
The currently best performing poker-playing programs are approximating a Nash equilibrium \cite{quality_of_bots}.
In game theory a Nash equilibrium describes a state of a game where no player can find an action that would yield a better outcome than the suggested equilibrium action, given that all other players also choose to take the suggested action \cite{game_theory}. \par
This strategy has proven to achieve great results in zero-sum games, like NL \pokerterm{heads-up} poker \cite{master_nuno}. Most successful heads-up poker bots use an abstract version of the poker variant in which they approximate the Nash equilibrium and then transfer the decision made in the abstract version to the real version of the game. One of the most successful algorithm in approximating the Nash equilibrium in an abstract version of the game is called \textit{Counterfactual Regret Minimization}. The top three poker bots in the \textit{Annual Computer Poker Competition} (ACPC) 2016 used a variant of the Counterfactual Regret (CFR) algorithm to defeat their competitors \cite{quality_of_bots}.
\section{Adaptive / Exploitive Poker Agents}
Nash equilibrium approaches and other static poker strategies are vulnerable to exploitation \cite{master_nuno}.
Adaptive strategies try to tackle this problem by quickly adapting to the playing-style of the opponents and exploiting their weaknesses. Two algorithms, namely the \textit{Miximax} and \textit{Miximix} algorithm achieve this by searching an adaptive imperfect information game tree. Decisions are then made by considering a \textit{randomized mixed strategy} associated with the decision node of the searched tree \cite{billings_phd}.%\TODOexplainindetail{Some more information on the success of those strategies?}
\section{Bayesian Poker Agents and Evolutionary Algorithms}
\subsection{Bayesian Poker Agents}
A Bayesian network is a probabilistic graphical model. Each node in the directed acyclic graph represents a random variable and edges between nodes represent the conditional dependencies of variables. Nodes are associated with a probability function which returns the conditional probability values based on their parent's values. A probability distribution over the random variables can be retrieved by propagating the probabilities of initialized nodes throughout the network \cite{review}. \par
Compared to other poker playing agents, bayesian agents performed badly in the AAAI Computer Poker Competitions in the last years. There is still a lot of room for improvement in Bayesian based networks and further research in this field has to be done to be competitive in upcoming competitions \cite{review}. 
\subsection{Evolutionary Algorithms}
Evolutionary algorithms try to mimic the evolution process of biological bodies. Agents of one generation are competing in a population to achieve a good score for a given task. The best agents are then evaluated and chosen as parents for the next generation. Some small changes are applied to the genetic information of the newly created offsprings before they compete with the best agents of the previous generation in a new population. This process repeats for a number of generations and optimally should yield a global increase of performance \cite{evolutionary_methods}.\par
Over the last years evolutionary algorithms were used in some studies to train artificial neural networks to play poker. Nicolai and Hilderman \cite{nn_evolve} train neural network agents to learn the game of poker and propose some methods to counter problems inherent in evolutionary algorithms. While poker agents trained with an evolutionary algorithm have not yet performed very well against other poker bots, there is still a lot to learn and discover from evolutionary algorithms applied to neural networks in the future \cite{review}. 
%\glsresetall %% all glossary entries should be used in long form (again)
%% vim:foldmethod=expr
%% vim:fde=getline(v\:lnum)=~'^%%%%\ .\\+'?'>1'\:'='
%%% Local Variables:
%%% mode: latex
%%% mode: auto-fill
%%% mode: flyspell
%%% eval: (ispell-change-dictionary "en_US")
%%% TeX-master: "main"
%%% End:
